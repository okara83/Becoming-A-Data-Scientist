{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark explode array and map columns to rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives an intro into explode array or list and map columns to rows using different PySpark DataFrame functions (explode, explore_outer, posexplode, posexplode_outer) with Python example.\n",
    "\n",
    "\n",
    " \n",
    "Before we start, let’s create a DataFrame with array and map fields, below snippet, creates a DF with columns 'name' as StringType, 'knownLanguage' as ArrayType and 'properties' as MapType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import explode_outer\n",
    "from pyspark.sql.functions import posexplode\n",
    "from pyspark.sql.functions import posexplode_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('MyPysparkExample').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explode – PySpark explode array or map column to rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark function explode(e: Column) is used to explode or create array or map columns to rows. When an array is passed to this function, it creates a new default column “col1” and it contains all array elements. When a map is passed, it creates two new columns one for key and one for value and each element in map split into the rows.\n",
    "\n",
    "This will ignore elements that have null or empty. from the above example, Washington and Jefferson have null or empty values in array and map, hence the following snippet out does not contain these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- knownLanguages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "+----------+--------------+--------------------+\n",
      "|      name|knownLanguages|          properties|\n",
      "+----------+--------------+--------------------+\n",
      "|     James| [Java, Scala]|[eye -> brown, ha...|\n",
      "|   Michael|[Spark, Java,]|[eye ->, hair -> ...|\n",
      "|    Robert|    [CSharp, ]|[eye -> , hair ->...|\n",
      "|Washington|          null|                null|\n",
      "| Jefferson|        [1, 2]|                  []|\n",
      "+----------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arrayData = [('James',['Java','Scala'],{'hair':'black','eye':'brown'}),\n",
    "        ('Michael',['Spark','Java',None],{'hair':'brown','eye':None}),\n",
    "        ('Robert',['CSharp',''],{'hair':'red','eye':''}),\n",
    "        ('Washington',None,None),\n",
    "        ('Jefferson',['1','2'],{})]\n",
    "\n",
    "df = spark.createDataFrame(data=arrayData, schema = ['name','knownLanguages','properties'])\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explode – array column example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- col: string (nullable = true)\n",
      "\n",
      "+---------+------+\n",
      "|     name|   col|\n",
      "+---------+------+\n",
      "|    James|  Java|\n",
      "|    James| Scala|\n",
      "|  Michael| Spark|\n",
      "|  Michael|  Java|\n",
      "|  Michael|  null|\n",
      "|   Robert|CSharp|\n",
      "|   Robert|      |\n",
      "|Jefferson|     1|\n",
      "|Jefferson|     2|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.select(df.name,explode(df.knownLanguages))\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explode – map column example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- key: string (nullable = false)\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "+-------+----+-----+\n",
      "|   name| key|value|\n",
      "+-------+----+-----+\n",
      "|  James| eye|brown|\n",
      "|  James|hair|black|\n",
      "|Michael| eye| null|\n",
      "|Michael|hair|brown|\n",
      "| Robert| eye|     |\n",
      "| Robert|hair|  red|\n",
      "+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df.select(df.name,explode(df.properties))\n",
    "df3.printSchema()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explode_outer – Create rows for each element in an array or map.<br>\n",
    "PySpark SQL explode_outer(e: Column) function is used to create a row for each element in the array or map column. Unlike explode, if the array or map is null or empty, explode_outer returns null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      name|   col|\n",
      "+----------+------+\n",
      "|     James|  Java|\n",
      "|     James| Scala|\n",
      "|   Michael| Spark|\n",
      "|   Michael|  Java|\n",
      "|   Michael|  null|\n",
      "|    Robert|CSharp|\n",
      "|    Robert|      |\n",
      "|Washington|  null|\n",
      "| Jefferson|     1|\n",
      "| Jefferson|     2|\n",
      "+----------+------+\n",
      "\n",
      "+----------+----+-----+\n",
      "|      name| key|value|\n",
      "+----------+----+-----+\n",
      "|     James| eye|brown|\n",
      "|     James|hair|black|\n",
      "|   Michael| eye| null|\n",
      "|   Michael|hair|brown|\n",
      "|    Robert| eye|     |\n",
      "|    Robert|hair|  red|\n",
      "|Washington|null| null|\n",
      "| Jefferson|null| null|\n",
      "+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name,explode_outer(df.knownLanguages)).show() # with array \n",
    "df.select(df.name,explode_outer(df.properties)).show() # with map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# posexplode – explode array or map elements to rows<br>\n",
    "posexplode(e: Column) creates a row for each element in the array and creates two columns “pos’ to hold the position of the array element and the ‘col’ to hold the actual array value. And when the input column is a map, posexplode function creates 3 columns “pos” to hold the position of the map element, “key” and “value” columns.\n",
    "\n",
    "This will ignore elements that have null or empty. Since the Washington and Jefferson have null or empty values in array and map, the following snippet out does not contain these.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|pos|   col|\n",
      "+---------+---+------+\n",
      "|    James|  0|  Java|\n",
      "|    James|  1| Scala|\n",
      "|  Michael|  0| Spark|\n",
      "|  Michael|  1|  Java|\n",
      "|  Michael|  2|  null|\n",
      "|   Robert|  0|CSharp|\n",
      "|   Robert|  1|      |\n",
      "|Jefferson|  0|     1|\n",
      "|Jefferson|  1|     2|\n",
      "+---------+---+------+\n",
      "\n",
      "+-------+---+----+-----+\n",
      "|   name|pos| key|value|\n",
      "+-------+---+----+-----+\n",
      "|  James|  0| eye|brown|\n",
      "|  James|  1|hair|black|\n",
      "|Michael|  0| eye| null|\n",
      "|Michael|  1|hair|brown|\n",
      "| Robert|  0| eye|     |\n",
      "| Robert|  1|hair|  red|\n",
      "+-------+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name,posexplode(df.knownLanguages)).show() # with array \n",
    "df.select(df.name,posexplode(df.properties)).show()   # with map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# posexplode_outer – explode array or map columns to rows.<br>\n",
    "Spark posexplode_outer(e: Column) creates a row for each element in the array and creates two columns “pos’ to hold the position of the array element and the ‘col’ to hold the actual array value. Unlike posexplode, if the array or map is null or empty, posexplode_outer function returns null, null for pos and col columns. Similarly for the map, it returns rows with nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|      name| pos|   col|\n",
      "+----------+----+------+\n",
      "|     James|   0|  Java|\n",
      "|     James|   1| Scala|\n",
      "|   Michael|   0| Spark|\n",
      "|   Michael|   1|  Java|\n",
      "|   Michael|   2|  null|\n",
      "|    Robert|   0|CSharp|\n",
      "|    Robert|   1|      |\n",
      "|Washington|null|  null|\n",
      "| Jefferson|   0|     1|\n",
      "| Jefferson|   1|     2|\n",
      "+----------+----+------+\n",
      "\n",
      "+----------+----+----+-----+\n",
      "|      name| pos| key|value|\n",
      "+----------+----+----+-----+\n",
      "|     James|   0| eye|brown|\n",
      "|     James|   1|hair|black|\n",
      "|   Michael|   0| eye| null|\n",
      "|   Michael|   1|hair|brown|\n",
      "|    Robert|   0| eye|     |\n",
      "|    Robert|   1|hair|  red|\n",
      "|Washington|null|null| null|\n",
      "| Jefferson|null|null| null|\n",
      "+----------+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\",posexplode_outer(\"knownLanguages\")).show() # with array \n",
    "df.select(df.name,posexplode_outer(df.properties)).show()# with map \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
