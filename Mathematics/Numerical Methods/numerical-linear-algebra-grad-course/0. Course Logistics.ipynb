{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Course Logistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teaching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Teaching Approach**\n",
    "\n",
    "I'll be using a *top-down* teaching method, which is different from how most math courses operate.  Typically, in a *bottom-up* approach, you first learn all the separate components you will be using, and then you gradually build them up into more complex structures.  The problems with this are that students often lose motivation, don't have a sense of the \"big picture\", and don't know what they'll need.\n",
    "\n",
    "Harvard Professor David Perkins has a book, [Making Learning Whole](https://www.amazon.com/Making-Learning-Whole-Principles-Transform/dp/0470633719) in which he uses baseball as an analogy.  We don't require kids to memorize all the rules of baseball and understand all the technical details before we let them play the game.  Rather, they start playing with a just general sense of it, and then gradually learn more rules/details as time goes on.\n",
    "\n",
    "All that to say, don't worry if you don't understand everything at first!  You're not supposed to.  We will start using some \"black boxes\" or matrix decompositions that haven't yet been explained, and then we'll dig into the lower level details later.\n",
    "\n",
    "To start, focus on what things DO, not what they ARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People learn by:\n",
    "1. **doing** (coding and building)\n",
    "2. **explaining** what they've learned (by writing or helping others)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Book**\n",
    "\n",
    "The book [**Numerical Linear Algebra**](https://www.amazon.com/Numerical-Linear-Algebra-Lloyd-Trefethen/dp/0898713617) by Trefethen and Bau is recommended.  The MSAN program has a few copies on hand.\n",
    "\n",
    "A secondary book is [**Numerical Methods**](https://www.amazon.com/Numerical-Methods-Analysis-Implementation-Algorithms/dp/0691151229) by Greenbaum and Chartier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that you have MathJax running (which renders LaTeX, used for math equations) by running the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ e^{\\theta i} = \\cos(\\theta) + i \\sin(\\theta)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that you can import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics Covered:\n",
    "\n",
    "1\\. Why are we here?\n",
    "  - Matrix and Tensor Products\n",
    "  - Matrix Decompositions\n",
    "  - Accuracy\n",
    "  - Memory use\n",
    "  - Speed\n",
    "  - Parallelization & Vectorization\n",
    "\n",
    "\n",
    "2\\. Topic Modeling with NMF and SVD\n",
    "  - Topic Frequency-Inverse Document Frequency (TF-IDF)\n",
    "  - Singular Value Decomposition (SVD)\n",
    "  - Non-negative Matrix Factorization (NMF)\n",
    "  - Stochastic Gradient Descent (SGD)\n",
    "  - Intro to PyTorch\n",
    "  - Truncated SVD, Randomized SVD\n",
    "\n",
    "\n",
    "3\\. Background Removal with Robust PCA\n",
    "  - Robust PCA\n",
    "  - Randomized SVD\n",
    "  - LU factorization\n",
    "\n",
    "\n",
    "4\\. Compressed Sensing for CT scans with Robust Regression\n",
    "  - L1 regularization\n",
    "\n",
    "\n",
    "5\\. Predicting Health Outcomes with Linear Regression\n",
    "  - Linear regression\n",
    "  - Polynomial Features\n",
    "  - Speeding up with Numba\n",
    "  - Regularization and Noise\n",
    "  - Implementing linear regression 4 ways\n",
    "\n",
    "\n",
    "6\\. PageRank with Eigen Decompositions\n",
    "  - Power Method\n",
    "  - QR Algorithm\n",
    "  - Arnoldi Iteration\n",
    "\n",
    "\n",
    "7\\. QR Factorization\n",
    "  - Gram-Schmidt\n",
    "  - Householder\n",
    "  - Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will review some linear algebra in class.  However, if you find there are concepts you feel rusty on, you may want to review on your own.  Here are some resources:\n",
    "\n",
    "- [3Blue1Brown Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) videos about *geometric intuition* (fantastic! gorgeous!)\n",
    "- Lectures 1-6 of Trefethen\n",
    "- [Immersive linear algebra](http://immersivemath.com/ila/) free online textbook with interactive graphics\n",
    "- [Chapter 2](http://www.deeplearningbook.org/contents/linear_algebra.html) of Ian Goodfellow's Deep Learning Book\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
