{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_decom(A, tol=0.0001):\n",
    "    n = A.shape[0]\n",
    "    vals,vecs = LA.eigh(A)\n",
    "    \n",
    "    inds = np.where((vals[1:] - vals[:-1]) > tol)[0]\n",
    "    starts = np.hstack([np.array([0]), inds+1])\n",
    "    ends = np.hstack([inds+1, np.array([n])])\n",
    "    \n",
    "    dist_vals = vals[starts]\n",
    "    projs = np.zeros((len(dist_vals), n, n))\n",
    "    i = 0\n",
    "    for s,e in zip(starts,ends):\n",
    "        space = vecs[:,s:e]\n",
    "        projs[i] = space.dot(space.T)\n",
    "        i += 1\n",
    "    \n",
    "    return dist_vals, projs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every $n\\times n$ symmetric matrix $A$, there is an orthogonal basis $\\beta = {\\{\\bf u}_1, \\ldots, {\\bf u}_n\\}$ and $n$ numbers $\\lambda_1,\\ldots,\\lambda_n$ such that $A{\\bf u}_i=\\lambda_i{\\bf u}_i$ for all $i$.  \n",
    "Recall that $\\lambda_i$'s are the eigenvalues and   \n",
    "${\\bf u}_i$'s are the eigenvectors.  \n",
    "We call $\\beta$ an **eigenbasis** of $A$.\n",
    "\n",
    "Let $Q$ be the matrix whose columns are vectors in $\\beta$ and $D$ the diagonal matrix whose diagonal entries are $\\lambda_1,\\ldots,\\lambda_n$.  Then  \n",
    "$$AQ = \n",
    "A\\begin{bmatrix}\n",
    " | & ~ & | \\\\\n",
    " {\\bf u}_1 & \\cdots & {\\bf u}_n \\\\\n",
    " | & ~ & | \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    " | & ~ & | \\\\\n",
    " \\lambda_1{\\bf u}_1 & \\cdots & \\lambda_n{\\bf u}_n \\\\\n",
    " | & ~ & | \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    " | & ~ & | \\\\\n",
    " {\\bf u}_1 & \\cdots & {\\bf u}_n \\\\\n",
    " | & ~ & | \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    " \\lambda_1 & ~ & ~ \\\\\n",
    " ~ & \\ddots & ~ \\\\\n",
    " ~ & ~ & \\lambda_n \n",
    "\\end{bmatrix} = \n",
    "QD.$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently, for every symmetric matrix $A$, there is an orthogonal matrix $Q$ and a diagonal matrix $D$ such that  \n",
    "$$A = QDQ^\\top \\text{ and } D = Q^\\top AQ$$  \n",
    "with $Q^\\top Q = QQ^\\top = I$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, $A$ can also be written as  \n",
    "$$A = QDQ^\\top = \\sum_{i = 1}^n \\lambda_i {\\bf u}_i{\\bf u}_i^\\top.$$  \n",
    "Note that each ${\\bf u}_i{\\bf u}_i^\\top$ is a projection matrix onto the straight line spanned by ${\\bf u}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `LA.eigh`\n",
    "- eigenbasis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "A = np.eye(3) - np.ones((3,3)) / 3\n",
    "vals,vecs = LA.eigh(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.eye(3) - np.ones((3,3)) / 3\n",
    "vals,vecs = LA.eigh(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.T.reshape(3,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.T.reshape(3,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(vals.reshape(3,1,1) * Q.T.reshape(3,3,1) * Q.T.reshape(3,1,3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.dot( Q.T.reshape(3,3,1) * Q.T.reshape(3,1,3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(a)\n",
    "Verify that $A = QDQ^\\top$ and $Q^\\top Q = QQ^\\top = I$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(b)\n",
    "Let ${\\bf u}$ be the $i$-th column of $Q$ and $\\lambda$ the $i$-th element of `vals`.  \n",
    "Verify that $A{\\bf u} = \\lambda{\\bf u}$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(c)\n",
    "Verify that \n",
    "$$A = \\sum_i \\lambda_i {\\bf u}_i{\\bf u}_i^\\top,$$  \n",
    "where $\\lambda_i$ is the $i$-th element of `vals` and ${\\bf u}_i$ is the $i$-th column of $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(d)\n",
    "Let  \n",
    "```python\n",
    "v = np.array([1,1,1])\n",
    "```\n",
    "What are the projections of ${\\bf v}$ onto ${\\bf u}_0$, ${\\bf u}_1$, and ${\\bf u}_2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(e)\n",
    "Find a matrix $B$ such that  \n",
    "$A{\\bf u}_0 = 2{\\bf u}_0$  \n",
    "$A{\\bf u}_1 = 2{\\bf u}_1$  \n",
    "$A{\\bf u}_2 = 3{\\bf u}_2$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "A = np.eye(3) - 2*np.ones((3,3)) / 3\n",
    "vals,vecs = LA.eigh(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "```\n",
    "Use `D` and `Q` to find the spectral decomposition of $A$.  \n",
    "Compare your answer with `spec_decom(A)` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 3\n",
    "Let $E$ be a matrix.  \n",
    "The **Frobenius norm** of $E$ is defined as $\\|E\\| = \\sqrt{\\operatorname{tr}(E^\\top E)}$.  \n",
    "\n",
    "Let  \n",
    "```python\n",
    "A = np.eye(3) - 2*np.ones((3,3)) / 3\n",
    "vals,vecs = LA.eigh(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(a)\n",
    "Pick a column vector ${\\bf u}$ of $Q$ and let $P = {\\bf u}{\\bf u}^\\top$.  \n",
    "Find $\\|P\\|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(b)\n",
    "Let  \n",
    "```python\n",
    "dist_vals, projs = spec_decom(A)\n",
    "```\n",
    "Pick a matrix $P$ in `projs` and find $\\|P\\|^2$.  \n",
    "If you look back at `vals`, can you guess the norm of each projection matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise 4\n",
    "Let  \n",
    "```python\n",
    "arr = plt.imread('circle.png')\n",
    "vals,vecs = LA.eigh(arr)\n",
    "```\n",
    "and $n = 216$.  \n",
    "Thus, `arr` is an $n\\times n$ matrix $A$.  \n",
    "Let $\\lambda_0\\leq\\ldots\\leq\\lambda_{n-1}$ be the eigenvalues of $A$ and ${\\bf u}_0,\\ldots {\\bf u}_{n-1}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4(a)\n",
    "Let  \n",
    "```python\n",
    "mask = (np.abs(vals) > 10)\n",
    "vals_m = vals[mask]\n",
    "vecs_m = vecs[:,mask]\n",
    "```\n",
    "How many eigenvalues of `arr` have their absolute values greater than $10$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(a)\n",
    "Let $S$ be a subset of $\\{0,\\ldots, n-1\\}$.  \n",
    "We have the inequality  \n",
    "$$\\|A - \\sum_{i\\in S} \\lambda_i{\\bf u}_i{\\bf u}_i^\\top\\| = \\|\\sum_{i\\notin S}\\lambda_i{\\bf u}_i{\\bf u}_i^\\top\\|\\leq \\sum_{i\\notin S}\\|\\lambda_i{\\bf u}_i{\\bf u}_i^\\top\\|\\leq \\sum_{i\\notin S}|\\lambda_i|.$$  \n",
    "\n",
    "In other words, we can approximate $A$ by $\\sum_{i\\in S} \\lambda_i{\\bf u}_i{\\bf u}_i^\\top$ for some subset $S$.  \n",
    "Let $S = \\{i: |\\lambda_i| > 10\\}$.  \n",
    "Calculate $\\sum_{i\\in S} \\lambda_i{\\bf u}_i{\\bf u}_i^\\top$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(b)\n",
    "Let `approx` be your previous answer.  \n",
    "Use `plt.imshow(approx, cmap='Greys_r')` to see if the approximation looks good or not.  \n",
    "Note that `arr` occupies $n\\times n$ units memory.  \n",
    "In contrast, if $|S| = k$, then $\\{\\lambda_i:i\\in S\\}$ occupies $k$ units of memory and $\\{{\\bf u}_i: i\\in S\\}$ occupies $n\\times k$ units of memory.  \n",
    "In total, `approx` can be stored with $(n+1)\\times k$ units of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5\n",
    "Let  \n",
    "```python\n",
    "A = np.array([[1,2,3],\n",
    "              [0,2,3],\n",
    "              [0,0,3]])\n",
    "vals,vecs = LA.eig(A)\n",
    "D = np.diag(vals)\n",
    "Q = vecs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5(a)\n",
    "Verify that $A = QDQ^{-1}$.  \n",
    "You may use `LA.inv` to calculate the inverse.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5(b)\n",
    "Let ${\\bf u}$ be the $i$-th column of $Q$ and $\\lambda$ the $i$-th element of `vals`.  \n",
    "Verify that $A{\\bf u} = \\lambda{\\bf u}$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
