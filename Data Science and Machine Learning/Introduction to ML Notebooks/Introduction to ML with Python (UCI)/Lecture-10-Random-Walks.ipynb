{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 10: Random Walks\n",
    "<br><br>\n",
    "Today we are going to simulate stochastic processes (time-dependent random data), and filled a numpy array with their discrete analogs (random walks). \n",
    "<br><br>\n",
    "Stochastic processes are random process evolving with time in a \"true\" or \"empirical\" stochastic/random fashion. Examples including: stock prices, the coordinate of a pollen in the water, the amount of cash in your wallet in a given Las Vegas casino, the acoustic data from an earthquake simulation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random # this is the non-vectorized random module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of vectorized generation of random numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some examples here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trick of vectorizing a boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(1*True) # what just happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(True+True) # what what what? wait what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model the coin flipping as a stochastic process\n",
    "\n",
    "Consider we want to simulate the following **stochastic process**.\n",
    "> Consider the following game: we start from the time $t_0 = 0$, at each subsequent $t_i=i$ ($i=1,2,\\dots$), we flip a coin. If the coin lands on head, we win $\\$ 1 $, otherwise we lose $\\$ 1$. Suppose $M_i$ denotes our money (in $\\$ $) in the wallet at $t_i$, and $M_0 = 0$ (when the money amount is $<0$, it means we owe money to the dealer).\n",
    "\n",
    "We want to model how $M_i$ evolves after 10000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coingame(num_flips):\n",
    "    money = np.zeros(num_flips+1)\n",
    "    for i in range(1,num_flips+1):\n",
    "        if random.random() > 0.5:\n",
    "            money[i] = money[i-1] + 1\n",
    "        else:\n",
    "            money[i] = money[i-1] - 1\n",
    "    return money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "money = coingame(1000)\n",
    "plt.plot(money[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized version of the simulation above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np.cumsum()\n",
    "def coingame_vec(num_flips):\n",
    "    coinflip = np.random.random(num_flips)\n",
    "    gain = 1.0*(coinflip < 0.5) - 1.0*(coinflip > 0.5) \n",
    "    # method 2\n",
    "    # gain = np.random.choice([-1.0, 1.0], size= num_flips, p = [0.4, 0.6])\n",
    "    # a nice trick to convert logical 1s and 0s (boolean) to floats\n",
    "    money = np.cumsum(gain)\n",
    "    return money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a few more simulation here\n",
    "for i in range(10):\n",
    "    money = coingame_vec(300)\n",
    "    plt.plot(money[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record multiple simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 300  # max length of a simulated random walk\n",
    "N = 1000  # number of simulation\n",
    "\n",
    "simulations = np.zeros([N,num_steps])\n",
    "\n",
    "for i in range(N):\n",
    "    simulations[i,:] = coingame_vec(num_steps) # each row stands for a simulation\n",
    "\n",
    "for j in range(100):\n",
    "    plt.plot(simulations[j,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a probability distribution that gets us some random $X$'s. We can then get a new probability distribution that takes a bunch of random $X$'s and gives the average:\n",
    "\n",
    "$$Y_n = \\frac{X_1 + X_2 + ... + X_n}{n},$$\n",
    "\n",
    "How are the $Y_n$'s distributed? \n",
    "\n",
    "For example, each $X_i$ represent the flipping result at $i$-th step. If it's heads, I win 1 dollar so $X_i=1$; if it's tails I lose 1 dollar, so $X_i = -1$. If I play this flipping game $n$ times, my average winning per game is $Y_n$. It's pretty clear that on average, I should break even, but how likely is it for my average winning per game will be high? What's the distribution of my per-game winnings if I play 100 games of coin-flipping?\n",
    "\n",
    "Let's take 1000 $Y_1$'s, 1000 $Y_2$'s, 1000 $Y_3$'s, ... and see what we get. Let's start by plotting the mean of each one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's design our experiment a little more carefully so that we can get the most information:\n",
    "\n",
    "* We are going to sample $Y_n$ 1000 times for $n=1,2,3,...,200$\n",
    "* We will plot the histogram of how $Y_n$ is distributed sometimes\n",
    "* We will record the mean each time.\n",
    "* We will record the standard deviation each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the histograam fitting function hist_and_fit. \n",
    "# a random variable's histogram is plotted, then we fit it using normal distribution.\n",
    "from math import sqrt, pi, e\n",
    "\n",
    "def hist_and_fit(X, num_bins=20):\n",
    "    # calculate mean and standard deviation. \n",
    "    mu = np.mean(X)\n",
    "    sigma = np.std(X)\n",
    "    \n",
    "    Z = np.linspace(-1,1,300)\n",
    "    plt.axis([-50,50,0,0.1])\n",
    "    plt.hist(X, num_bins, density=True, edgecolor = 'black')  \n",
    "    guassian_func = lambda mu, sigma: lambda x: 1/(sqrt(2*pi)*sigma) * e**(-0.5*(x - mu)*(x-mu)/(sigma * sigma))\n",
    "    plt.plot(Z, guassian_func(mu, sigma)(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "N = 1000 # number of sampling experiments\n",
    "num_steps = 200 # each experiment has 200 steps\n",
    "\n",
    "means = np.zeros(num_steps) # initialization\n",
    "stdevs = np.zeros(num_steps) # initialization\n",
    "\n",
    "\n",
    "\n",
    "for n in range(1, num_steps):\n",
    "     # Y_n is the average winning for n flippings for N = 1000 simulations\n",
    "    Y_n = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        Y_n[i] = np.sum(np.random.choice([-1,1], size= n)) / n # average gain at each n\n",
    "    means[n] = np.mean(Y_n)\n",
    "    stdevs[n] = np.std(Y_n)\n",
    "    if n % 40 == 0:\n",
    "        plt.figure()\n",
    "        plt.title(\"n=\" + str(n) + \", mean=\" + str(means[n])[:10] +  \", stdev= \" + str(stdevs[n])[:5])\n",
    "        hist_and_fit(Y_n, 20)\n",
    "        plt.axis([-1,1,0,8])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "The following code vectorizes the code above, no `for` is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized version of the code above here\n",
    "## YY_n represent the average gain for all N simulations at each time step n\n",
    "# YY_n[i,:] the i-th row of YY_n represent the average gain at each time step n for the i-th simulation \n",
    "YY_n = np.zeros([N, num_steps])\n",
    "np.random.seed(12345)\n",
    "flips = np.random.choice([-1,1], size= (N, num_steps))\n",
    "YY_n = np.cumsum(flips, axis = 1)/range(1,num_steps+1)\n",
    "means = np.mean(YY_n, axis = 0)\n",
    "stdevs = np.std(YY_n, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot\n",
    "for n in range(1, num_steps):    \n",
    "    if n % 40 == 0:\n",
    "        plt.figure()\n",
    "        plt.title(\"n=\" + str(n) + \", mean=\" + str(means[n])[:10] +  \", stdev= \" + str(stdevs[n])[:5])\n",
    "        hist_and_fit(YY_n[:,n], 10)\n",
    "        plt.axis([-1,1,0,8])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "* Looks like the distribution of $Y_n$'s is centered at zero. \n",
    "* The distribution of $Y_n$'s is looking sharper and sharper, more and more likely to be concentrated at zero as $n$ increases.\n",
    "* The distribution of $Y_n$'s is looking more and more like a normal distribution\n",
    "\n",
    "If we take $n \\rightarrow \\infty$..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Theorem**: (Law of large numbers) \n",
    "If we have $X_1,...,X_n$ from the same probability distribution $X$, and look at the probability distribution of the average:\n",
    "\n",
    "$$Y_n = \\frac{X_1 + X_2 + ... + X_n}{n},$$\n",
    "\n",
    "then, as $n$ goes to infinity, $Y_n$ approaches the constant probability distribution that always gives $\\mu$, the mean of $X$ the probability 1.\n",
    "In other words, the probability \n",
    "\n",
    "$$P\\Big(\\lim_{n\\rightarrow \\infty} Y_n = \\mu \\Big) = 1$$\n",
    "\n",
    "<br>\n",
    "\n",
    "*Remark*: This is regardless of what probability density $X$ has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,num_steps), means[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,num_steps), stdevs[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(range(1,num_steps), stdevs[1:], 'bo-', markersize = 3)\n",
    "plt.plot(range(1,num_steps), 1 / np.sqrt(np.arange(1,num_steps)), 'r', linewidth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as $n\\rightarrow \\infty$, the mean of the nth average is going to 0 (the mean of the original distribution) and the standard deviation is going to $\\frac{1}{\\sqrt{n}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Central Limit Theorem** \n",
    "Let $X_n$ be coming from a probability distribution with mean $\\mu$ and standard deviation $\\sigma$, and let\n",
    "\n",
    "$$Y_n = \\frac{X_1 + X_2 + ... + X_n}{n},$$\n",
    "\n",
    "be the average. As $n \\rightarrow \\infty$, the distribution of $Y_n$ approaches the normal distribution:\n",
    "\n",
    "$$N\\left(\\mu, \\Big(\\frac{\\sigma}{\\sqrt{n}} \\Big)^2\\right)$$\n",
    "\n",
    "with mean $\\mu$ and standard deviation $\\frac{\\sigma}{\\sqrt{n}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remark: \n",
    "Note that this is independent of the original shape of $X$. This means that if you have many many things averaging out, you are certain to get a normal distribution! That's why normal distribution is the most standard distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-class exercise\n",
    "Now suppose the coin is a biased one with $p = 0.6$.\n",
    "Repeat the simulations above using\n",
    "```python\n",
    "np.random.choice([-1, 1], size=num_steps, p=[0.4, 0.6])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
