{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 16: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem setting\n",
    "\n",
    "## Review\n",
    "In last few lectures we have learned the linear regression, where we explore the possibility of using a linear function (or higher degree polynomials) to represent the relation of the features in the samples (aka labels, $x$ values, or training data `X_train`) to a target value ($y$ values `y_train`), so that we can predict the target value $y$ (`y_pred` obtained by the model) based on testing data `X_test`.\n",
    "\n",
    "However, linear regression is not appropriate in the case of a qualitative target value.\n",
    "\n",
    "## Classification\n",
    "Today, we will learn how to predict a discrete label such as \n",
    "* predicting whether a grid of pixel intensities represents a \"0\" digit or a \"1\" digit;\n",
    "* predicting whether tomorrow will have rain based on previous days' data.\n",
    "* predicting whether a wine is good or mediocre based on its chemical components' data.\n",
    "\n",
    "This is a classification problem. Logistic regression is a simple classification algorithm for learning to make such decisions for a binary label.\n",
    "\n",
    "Reference: MATLAB tutorial in [Stanford Deep Learning tutorial](http://deeplearning.stanford.edu/tutorial/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "----\n",
    "\n",
    "## Heuristics\n",
    "Recall the `winequality-red.csv` we have used in the last few lectures and labs. If the `quality` of a wine is $\\geq 6$, relabel it as \"favorable\"; if the `quality` of a wine is $\\leq 5$, relabel it as \"mediocre\". \n",
    "\n",
    "For a certain sample $(\\mathbf{x}^{(i)}, y^{(i)})$, where $\\mathbf{x}^{(i)}$ is the vector representing its first 11 features, and $y^{(i)}$ is the quality score (label), if we know its score is 7, then\n",
    "$$\n",
    "P\\big(i\\text{-th sample is favorable} \\big) = 1, \\qquad \n",
    "P\\big(i\\text{-th sample is mediocre} \\big) = 0. \n",
    "$$\n",
    "If we relabel the \"favorable\" and \"mediocre\" into 1 and 0 as our values for $y^{(i)}$, then\n",
    "$$\n",
    "P\\big(y^{(i)} = 1\\big) = 1, \\qquad P\\big(y^{(i)} = 0\\big) = 0.\n",
    "$$\n",
    "If some other sample, say $j$-th sample, has quality score 4, then\n",
    "$$\n",
    "P\\big(y^{(j)} = 1\\big) = 0, \\qquad P\\big(y^{(j)} = 0\\big) = 1.\n",
    "$$\n",
    "We can use vector $[1,0]$ to represent the first sample's probability in each class, and vector $[0,1]$ to represent that of the second sample.\n",
    "\n",
    "We want to build a model, so that given the first 11 features $\\mathbf{x}$ of a certain sample, it can output an estimate, say, $[0.8, 0.2]$ to tell me that \n",
    "$$\n",
    "P\\big(y = 1| \\mathbf{x}\\big) = 0.8, \\qquad P\\big(y = 0|\\mathbf{x}\\big) = 0.2,\n",
    "$$\n",
    "which is to say, this sample has 0.8 chance in Class 1, 0.2 chance in the Class 0. The predicted label $\\hat{y}$ is then:\n",
    "$$\n",
    "\\hat{y} = \\operatorname{arg}\\max_{j} P\\big(y = j| \\mathbf{x}\\big),\n",
    "$$\n",
    "i.e., we use the biggest estimated probability's class as this sample's predicted label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "## Model function (hypothesis)\n",
    "\n",
    "Weights vector $\\mathbf{w}$, same shape with a sample's feature vector $\\mathbf{x}$, $h(\\mathbf{x})$ is our estimate of $ P(y=1|\\mathbf{x})$ and $1 - h(\\mathbf{x})$ is our estimate of $P(y=0|\\mathbf{x}) = 1 - P(y=1|\\mathbf{x})$.\n",
    "\n",
    "$$\n",
    "h(\\mathbf{x}) = h(\\mathbf{x};\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^\\top \\mathbf{x})}\n",
    "=: \\sigma(\\mathbf{w}^\\top \\mathbf{x}) \n",
    "$$\n",
    "or more compactly, because $y = 0$ or $1$:\n",
    "$$\n",
    "P(y|\\mathbf{x}) \\text{ is estimated by } h(\\mathbf{x})^y \\big(1 - h(\\mathbf{x}) \\big)^{1-y}.\n",
    "$$\n",
    "\n",
    "----\n",
    "\n",
    "## Loss function\n",
    "\n",
    "$$\n",
    "L (\\mathbf{w}; X, \\mathbf{y}) = - \\frac{1}{N}\\sum_{i=1}^N \n",
    "\\Bigl\\{y^{(i)} \\ln\\big( h(\\mathbf{x}^{(i)}; \\mathbf{w}) \\big) \n",
    "+ (1 - y^{(i)}) \\ln\\big( 1 - h(\\mathbf{x}^{(i)};\\mathbf{w}) \\big) \\Bigr\\}.\n",
    "\\tag{$\\star$}\n",
    "$$\n",
    "\n",
    "----\n",
    "\n",
    "## Training\n",
    "\n",
    "The gradient of the loss function with respect to the weights $\\mathbf{w}$ is:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} \\big( L (\\mathbf{w}) \\big) \n",
    "=\\frac{1}{N}\\sum_{i=1}^N \\big( h(\\mathbf{x}^{(i)};\\mathbf{w})  - y^{(i)} \\big) \\mathbf{x}^{(i)}  . \\tag{$\\dagger$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model h(X; w) = sigma(-Xw)\n",
    "# w: weights\n",
    "# X: training data\n",
    "# X.shape[0] is no. of samples, and X.shape[1] is the no. of features\n",
    "def h(X,w):\n",
    "    z = np.matmul(X,w)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "# loss function, modulo by N (size of training data), a vectorized implementation without for loop\n",
    "def loss(w,X,y):\n",
    "    loss_components = np.log(h(X,w)) * y + (1.0 - y)* np.log(1 - h(X,w))\n",
    "    # above is a dimension (12665,) array\n",
    "    return -np.mean(loss_components) # same with loss_components.sum()/N\n",
    "\n",
    "def gradient_loss(w,X,y):\n",
    "    gradient_for_all_training_data = (h(X,w) - y).reshape(-1,1)*X\n",
    "    # we should return a (n,) array, which is averaging all N training data's gradient\n",
    "    return np.mean(gradient_for_all_training_data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading 1: Derivation of the logistic regression\n",
    "\n",
    "For binary-valued labels, $y^{(i)} \\in \\{0,1\\}$, we are trying to predict the probability that a given example belongs to the \"1\" class versus the probability that it belongs to the \"0\" class. Specifically, we will use the **logistic regression**, which tries to learn a function of the form:\n",
    "\n",
    "$$\n",
    "h(\\mathbf{x}) = h(\\mathbf{x};\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^\\top \\mathbf{x})}\n",
    "=: \\sigma(\\mathbf{w}^\\top \\mathbf{x}) \n",
    "$$\n",
    "or more compactly, because $y = 0$ or $1$:\n",
    "$$\n",
    "P(y|\\mathbf{x}) = h(\\mathbf{x})^y \\big(1 - h(\\mathbf{x}) \\big)^{1-y}\n",
    "$$\n",
    "\n",
    "----\n",
    "\n",
    "## Sigmoid function\n",
    "The function $\\sigma(z) = 1/\\big(1+\\exp(−z)\\big)$ is often called the \"sigmoid\" or \"logistic\" function, or \"logistic/sigmoid\" activation function in machine learning. It is an S-shaped function that \"squashes\" the value of $\\mathbf{w}^\\top \\mathbf{x}$ into the range $[0,1]$ so that we may interpret $h(\\mathbf{x})$ as a probability. \n",
    "\n",
    "Our goal is to search for a value of the weights $\\mathbf{w}$ so that:\n",
    "> The probability $P(y=1|\\mathbf{x})=h(\\mathbf{x})$ is large when $x$ belongs to the \"1\" class, small when $x$ belongs to the \"0\" class (so that $P(y=0|\\mathbf{x})=1- h(\\mathbf{x})$ is large). \n",
    "\n",
    "----\n",
    "\n",
    "## Maximum likelihood\n",
    "For a set of training examples with binary labels $\\{(\\mathbf{x}^{(i)},y^{(i)}):i=1,\\dots,N\\}$ the following likelihood estimator measures how well a given model $h(\\mathbf{x};\\mathbf{w})$ does this separating class job: assuming our training samples are independently Bernoulli distributed, we want to maximize the following quantity\n",
    "$$\n",
    "{\\begin{aligned}\n",
    "&P(\\mathbf{y}\\; | \\; \\mathbf{X};\\mathbf{w} )\\\\\n",
    "=&\\prod _{i=1}^N P\\left(y^{(i)}\\mid \\mathbf{x}^{(i)};\\mathbf{w}\\right)\\\\\n",
    "=&\\prod_{i=1}^N h\\big(\\mathbf{x}^{(i)} \\big)^{y^{(i)}} \n",
    "\\Big(1-h\\big(\\mathbf{x}^{(i)}\\big) \\Big)^{\\big(1-y^{(i)}\\big)}\n",
    "\\end{aligned}}.\n",
    "$$\n",
    "This function is highly nonlinear on the weights $\\mathbf{w}$ so we take the log and then average, lastly define our loss function to be minimized as follows:\n",
    "$$\n",
    "L (\\mathbf{w}) = L (\\mathbf{w}; X,\\mathbf{y}) = - \\frac{1}{N}\\sum_{i=1}^N \n",
    "\\Bigl\\{y^{(i)} \\ln\\big( h(\\mathbf{x}^{(i)}) \\big) \n",
    "+ (1 - y^{(i)}) \\ln\\big( 1 - h(\\mathbf{x}^{(i)}) \\big) \\Bigr\\}.\n",
    "\\tag{$\\star$}\n",
    "$$\n",
    "Note that only one of the two terms in the summation is non-zero for each training sample (depending on whether the label $y^{(i)}$ is 0 or 1). When $y^{(i)}=1$ minimizing the loss function means we need to make $h(x^{(i)})$ large, and when $y^{(i)}= 0$ we want to make $1- h(x^{(i)})$ large as explained above. \n",
    "\n",
    "----\n",
    "\n",
    "## Training and cross-validation\n",
    "After the loss function $L (\\mathbf{w})$ is set up, the training data is used by the gradient descent to minimize $L (\\mathbf{w})$ to find the best choice of weights $\\mathbf{w}$. Even though the cost function $(\\star)$ looks quite complicated, due to the following special property of the Sigmoid function \n",
    "$$\n",
    "\\frac{d}{dz} \\big(\\sigma(z)\\big)\n",
    " = \\frac{d}{dz} \\left(\\frac{1}{1+\\exp(−z)}\\right) = \\sigma(z)\\cdot \\big(1-\\sigma(z)\\big).\n",
    "$$\n",
    "Therefore recalling $h(\\mathbf{x}) =  \\sigma(\\mathbf{w}^\\top \\mathbf{x})$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L (\\mathbf{w})}{\\partial w_k} & = \n",
    "- \\frac{1}{N}\\sum_{i=1}^N \n",
    "\\Bigg\\{y^{(i)}  \\frac{1}{h(\\mathbf{x}^{(i)})} \\frac{\\partial}{\\partial w_k} \\sigma\\big(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}  \\big)\n",
    "+ (1 - y^{(i)}) \\frac{1}{1-h(\\mathbf{x}^{(i)})} \\frac{\\partial}{\\partial w_k}\\Big(1-  \\sigma\\big(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}\\big)  \\Big) \\Bigg\\}\n",
    "\\\\\n",
    "& = - \\frac{1}{N}\\sum_{i=1}^N \n",
    "\\Bigg\\{y^{(i)}  \\frac{1}{h(\\mathbf{x}^{(i)})} \n",
    "\\sigma\\big(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}\\big) \n",
    "\\cdot \\big(1-\\sigma(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)})\\big) \n",
    "\\frac{\\partial}{\\partial w_k} \\sigma\\big(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}  \\big)\n",
    "\\\\\n",
    "& \\qquad \\qquad - (1 - y^{(i)}) \\frac{1}{1-h(\\mathbf{x}^{(i)})} \n",
    "\\sigma\\big(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}\\big) \n",
    "\\cdot \\big(1-\\sigma(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)})\\big) \n",
    "\\frac{\\partial}{\\partial w_k}\\big(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}\\big)  \\Bigg\\}\n",
    "\\\\\n",
    "& = - \\frac{1}{N}\\sum_{i=1}^N \n",
    "\\Bigg\\{y^{(i)} \\cdot \\big(1-\\sigma(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)})\\big) \n",
    "\\frac{\\partial}{\\partial w_k} \\sigma\\big(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}  \\big)\n",
    "- (1 - y^{(i)}) \\cdot\n",
    "\\sigma(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}) \n",
    "\\frac{\\partial}{\\partial w_k}\\big(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}\\big)  \\Bigg\\}\n",
    "\\\\\n",
    "& =\\frac{1}{N}\\sum_{i=1}^N  \\big(\\sigma(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)})  - y^{(i)} \\big) x^{(i)}_k.\n",
    "\\end{aligned}\n",
    "$$\n",
    "The final expression is pretty simple, basically the derivative of the Logistic loss function w.r.t. the $k$-th weight $w_k$ is the sum of the residuals $\\big(\\sigma(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)})  - y^{(i)} \\big) $ multiply with the $k$-th component in the $i$-th training data $\\mathbf{x}^{(i)}$.\n",
    "\n",
    "Therefore the gradient for all the weights $\\mathbf{w}$ is then:\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} \\big( L (\\mathbf{w}) \\big) = \\sum_{i=1}^N  \\big(\\sigma(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)})  - y^{(i)} \\big) \\mathbf{x}^{(i)} \n",
    "=\\frac{1}{N}\\sum_{i=1}^N \\big( h(\\mathbf{x}^{(i)})  - y^{(i)} \\big) \\mathbf{x}^{(i)}  . \\tag{$\\dagger$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading 2: Bayesian classification\n",
    "\n",
    "What we have learned above, the logistic regression and softmax regression, are two classification methods that are closely related to Bayesian classifiers. Because essentially, we are trying minimize the following the error associated with a set of observations of the form in a way (by introducing some model with weights):\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{w}} \\Big[\\text{Mean of } 1\\big\\{y^{(i), \\text{Pred}} \\neq y^{(i), \\text{Actual}} \\big\\} \\Big],\n",
    "$$\n",
    "\n",
    "If there is no model yet, let $K= \\# \\text{ classes}$. Keep in mind for now there are no weights involved, we simply want to classify the samples into $K$ classes, so that the minimization of problem above is *assigning each sample to the most likely class it belongs to*, given its values (feature vector), i.e., we want to compute\n",
    "\n",
    "$$\n",
    "\\max_{j\\in \\{1,\\dots ,K\\}} P\\big(y^{(i)}=j | \\mathbf{x}^{(i)} \\big)  \\tag{$\\diamond$}\n",
    "$$\n",
    "\n",
    "where $P\\big(y^{(i)}=j | \\mathbf{x}^{(i)} \\big)$ is the conditional probability that the label $y^{(i)}=j$ (the $i$-th sample is in the $j$-th class), given the observed vector $\\mathbf{x}^{(i)}$ for the $i$-th sample. This is called the naive Bayes classifier. \n",
    "\n",
    "----\n",
    "\n",
    "### Naive Bayes classifier\n",
    "\n",
    "Using the definition of the conditional probability: for an arbitrary sample and its label $(\\mathbf{x},y)$\n",
    "\n",
    "$$\n",
    "P(y=j | \\mathbf {x} )={\\frac { P( y = j, \\mathbf {x})}{P(\\mathbf {x} )}} \\tag{$\\ast$}\n",
    "$$\n",
    "\n",
    "Assuming $\\mathbf{x} = (x_1, x_2, \\dots, x_n)$, i.e., each sample has $n$ features, then the numerator above is \n",
    "$ P(y=j)\\ P(\\mathbf {x} | y = j)$, where $P(y=j)$ is the probability that an arbitrary sample is of class $j$ without any observation $\\mathbf{x}$, i.e., $P(y=j)$ is the portion of class $j$ against all all samples. Now using the definition of conditional probability again:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(y=j,x_{1},\\dots ,x_{n}) &= P(x_{1},\\dots ,x_{n},y=j)\n",
    "\\\\\n",
    "&= P(x_{1} | x_{2},\\dots ,x_{n},y=j) P(x_{2},\\dots ,x_{n},y=j)\n",
    "\\\\\n",
    "&= P(x_{1} | x_{2},\\dots ,x_{n},y=j) P(x_{2} | x_{3},\\dots ,x_{n},y=j) P(x_{3},\\dots ,x_{n},y=j)\n",
    "\\\\&=\\dots \n",
    "\\\\&= P(x_{1} |  x_{2},\\dots ,x_{n},y=j) P(x_{2} | x_{3},\\dots ,x_{n},y=j)\n",
    "\\dots P(x_{n-1} | x_{n},y=j) P(x_{n}| y=j)P(y=j)\\\\\n",
    "\\end{aligned} \\tag{$\\ast\\ast$}\n",
    "$$\n",
    "\n",
    "Assuming each feature is independent from one another, which means whether put $x_l$ ($l\\neq i$) into the given observed conditions does not affect the probability of $x_i$:\n",
    "$$\n",
    "P(x_{i} | x_{i+1},\\dots ,x_{n}, y =j) = P(x_{i}| y=j).\n",
    "$$\n",
    "\n",
    "Since $P(\\mathbf{x}) = 1/N$ is a fixed value (assuming uniform distributed sample), we have by $(\\ast)$ and $(\\ast\\ast)$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(y=j | x_{1},\\dots ,x_{n}) &\\propto P(y=j,x_{1},\\dots ,x_{n})\n",
    "\\\\\n",
    "&=P(y=j)\\ P(x_{1} | y=j)\\ P(x_{2}| y=j)\\ P(x_{3} | y=j)\\ \\cdots \n",
    "\\\\\n",
    "&=P(y=j)\\prod_{i=1}^{n}P(x_{i}| y=j),\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now for training sample $\\mathbf{x}^{(i)}$, the problem becomes:\n",
    "\n",
    "$$\n",
    "y^{(i), \\text{Pred}}={\\underset {j\\in \\{1,\\dots ,K\\}}{\\operatorname {argmax} }}\\ P(y = j)\\displaystyle \\prod _{i=1}^{n} P(x_{i} | y=j),\n",
    "$$\n",
    "\n",
    "where $y^{(i), \\text{Pred}}$ is the class which the probability $(\\diamond)$ is maximized.\n",
    "\n",
    "----\n",
    "\n",
    "### Pitfalls of naive Bayes classifier\n",
    "\n",
    "In reality, there are two main reasons the method above is neither practical nor reasonable.\n",
    "\n",
    "* there is no way $x_i$ and $x_l$ are independent when $i\\neq l$ for a sample $\\mathbf{x}$. Think in the handwritten digit classification example, $x_i$'s are the pixel intensity at $i$-th location (one of the pixel among 28x28 reshaped into a 784 array), any reasonable ansatz should not assume independency, because the pixel intensity are determined by the strokes.\n",
    "* For real data, we do not know $P(y=j)$'s true value, i.e., percentage of the samples in class $k$, because new data may come in. For the same reason $P(x_{i} | y=j)$ is not known either.\n",
    "\n",
    "Therefore, we introduce a model (an a priori assumption that the data can be described by such a model) with weights $\\mathbf{w}$, and the problem changes to (softmax case) the following maximization of the log of the likehood function (or say cross entropy),\n",
    "$$\n",
    "\\max_{\\mathbf{w}}\\sum_{i=1}^N \\left\\{\\sum_{j=1}^K\n",
    " 1_{\\{y^{(i)} = j\\}} \\ln P\\big(y^{(i)}=j | \\mathbf{x}^{(i)} ; \\mathbf{w} \\big) \\right\\},\n",
    "$$\n",
    "in Lecture 15, 16, 17, we will try using gradient descent to minimize the negative version of above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
