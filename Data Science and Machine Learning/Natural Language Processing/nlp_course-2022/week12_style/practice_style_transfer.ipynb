{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice_style_transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/justheuristic/324eeb95796c6cf90bab7355af00d32b/practice_style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYvnVzA2DmIu"
      },
      "source": [
        "### Week 10 - text style transfer\n",
        "\n",
        "Hello, sitzen class A.412C!\n",
        "\n",
        "Based on your browser search history, we conclude that you have an above average skill in natural language processing. In our benevolence, we give you a chance to contribute your skills to upholding the happiest society in the universe. Are you up to the task?\n",
        "\n",
        "As you know, our most recent breakthrough was replacing 97% restaurant workers with BFGHQBERT+++ autonomous food dispensers.\n",
        "\n",
        "Yet a some radical elements failed to recognize the greater good that we brought them. They mistakenly voice their ignorant opinions about our new INGSOC-approved restaurants, brining dangerous doubt to the minds of our loyal citzens.\n",
        "\n",
        "Surely you cannot tolerate such infidelity! Our loyal citzens demand that you rectify their mistake. _You must build a model that will automatically improve their ignorant thoughts and replace them with the thoughts they should actually have._\n",
        "\n",
        "Attached below are the INGSOC-approved datasets for ignorant and correct thoughts. The scientific terminology is for wrong opinions and correct opinions is \"negative\" and \"positive\", respectively.\n",
        "\n",
        "Respond within 7 days or you will lose 3.7629 citzenship points.\n",
        "\n",
        "![img](https://ih1.redbubble.net/image.1254830934.9884/poster,504x498,f8f8f8-pad,400x240,f8f8f8.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z63QypDjVmIe"
      },
      "source": [
        "!pip install -q transformers\n",
        "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.train.0 -O train_negative\n",
        "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.train.1 -O train_positive\n",
        "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.dev.0 -O dev_negative\n",
        "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.dev.1 -O dev_positive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQADoMFcU5cU",
        "outputId": "e5491972-b773-4e0b-e4db-88fb8180fda4"
      },
      "source": [
        "!head -n 5 ./dev_positive\n",
        "!echo\n",
        "!head -n 5 ./dev_negative"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "staff behind the deli counter were super nice and efficient !\n",
            "love this place !\n",
            "the staff are always very nice and helpful .\n",
            "the new yorker was amazing .\n",
            "very ny style italian deli .\n",
            "\n",
            "ok never going back to this place again .\n",
            "easter day nothing open , heard about this place figured it would ok .\n",
            "the host that walked us to the table and left without a word .\n",
            "it just gets worse .\n",
            "the food tasted awful .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MTzCt4i6BE-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "if device == 'cpu':\n",
        "    print(\"Fine-tuning BERT without an accelerator is not party-approved.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGhzg7qKKdqX"
      },
      "source": [
        "### Part 1: Masked language model\n",
        "\n",
        "Attached below you can find the INGSOC-compliant training code that fine-tunes a BERT model for Masked Language Modeling.\n",
        "\n",
        "You shall use this model to generate positive replacements for negative tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhhZG7YMVihR"
      },
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_mlm_positive = BertForMaskedLM.from_pretrained('bert-base-uncased', return_dict=True).to(device).train(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Ir_RGWBWMF"
      },
      "source": [
        "from transformers import LineByLineTextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "print(\"Preparing the training data...\")\n",
        "dataset = LineByLineTextDataset(\n",
        "    file_path=\"./train_positive\", tokenizer=tokenizer, block_size=128)\n",
        "\n",
        "print(\"Dataset ready!\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=bert_mlm_positive, train_dataset=dataset, \n",
        "    data_collator=DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15),\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"./bert_mlm_positive\", overwrite_output_dir=True,\n",
        "        num_train_epochs=1, per_device_train_batch_size=32,\n",
        "        save_steps=10_000, save_total_limit=2),\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO0jC8_7OWrq"
      },
      "source": [
        "# <Build and train a MLM for incorrect opinions>\n",
        "\n",
        "bert_mlm_negative = <...>\n",
        "\n",
        "<A whole lot of your code>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_IQohMhO63b"
      },
      "source": [
        "### Part 2: Replace tokens\n",
        "\n",
        "You can now use the two masked language models to align user opinions. You can do so with the following steps:\n",
        "\n",
        "1. Find tokens where the ratio $(P_{positive}(x) + \\epsilon) / (P_{negative}(x) + \\epsilon)$ is the smallest\n",
        "2. Replace those tokens with one of $k$ most likely tokens according to $P_{positive}(x)$.\n",
        "3. Rinse, repeat\n",
        "\n",
        "You can find the full procedure at https://arxiv.org/abs/2010.01054"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVfJC5_kRskk"
      },
      "source": [
        "def get_replacements(sentence: str, num_tokens, k_best, epsilon=1e-3):\n",
        "  \"\"\"\n",
        "  - split the sentence into tokens using the INGSOC-approved BERT tokenizer\n",
        "  - find :num_tokens: tokens with the highest ratio (see above)\n",
        "  - replace them with :k_best: words according to bert_mlm_positive\n",
        "  :return: a list of all possible strings (up to k_best * num_tokens)\n",
        "  \"\"\"\n",
        "  <YOUR CODE HERE>\n",
        "\n",
        "  return <...>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RJptvlOTfs4"
      },
      "source": [
        "dev_data = list(open('./dev_negative'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2UlAc6QToKD"
      },
      "source": [
        "dev_data[500:505]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXEuVoTmTSV-"
      },
      "source": [
        "get_replacements(\"great wings and decent drinks but the wait staff is horrible !\",\n",
        "                 num_tokens=1, k_best=2)\n",
        "# >>> [\"great wings and decent drinks but the wait staff is great !\", \"great wings and decent drinks but the wait staff is awesome !\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZvy3rECWMZB"
      },
      "source": [
        "__Final task__ - build a procedure that iteratively applies replacements, demonstrate the effectiveness of your approach with at least 10 examples to satisfy INGSOC.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIpWUOkvUAdi"
      },
      "source": [
        "<YOUR CODE HERE>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx831HfdMRh4"
      },
      "source": [
        "### Part 3: Classifier & beam search (5 pts)\n",
        "\n",
        "Sometimes the roots of dissent too deep to rip out with single word replacements. If you truly are a class A412C citzen, surely you understand what it means.\n",
        "\n",
        "In order to better serve your fellow citzens, you must improve your solution. Train a classifier model that will separate the negative (ignorant) opinions from positive ones.\n",
        "\n",
        "With this classifier you can now generate multiple best hypotheses and search for the ones that have the highest $P_{classifier}(\\text{positive} | x)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SIs5VJlBa3l"
      },
      "source": [
        "from transformers import BertForSequenceClassification, DataCollatorWithPadding\n",
        "\n",
        "<YOUR CODE HERE - build and train the classifier model>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJszzV_yYnf7"
      },
      "source": [
        "# your final task is to build a beam search-like procedure that iteratively\n",
        "# generates candidates using MLM and selects M best with classifier\n",
        "\n",
        "# as before, your fellow citzens request that you show your loyalty by \n",
        "# writing a short report on how your method works and demonstrating\n",
        "# the effectiveness of your system works with at least 10 examples\n",
        "\n",
        "# Note: as a class >=A410 citzen, you are entitled to creativity level 2.1:\n",
        "# you may modify the search objective by using language models, different search procedures\n",
        "# or implement a completely different style transfer method.\n",
        "\n",
        "<OBEY HERE>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t8PLGXze42Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 4 Deployment! (5 points)\n",
        "\n",
        "By now you have built a model that can change the style of your reviews. But what of the others? There's circa 8 Billion of us and only one of you, so it is only right that you share your invention with everyone of us.\n",
        "\n",
        "Your final task is to __build a web interface around your model that others can use in their browser__.\n",
        "\n",
        "There are many ways you can do so, one of them being TensorFlow.js we learned a few weeks ago. You can solve this task any way you want _provided that an INGSOC-certified teaching assistant will be able to view it in their browser_.\n",
        "Below we cover one (arguably) simplest way using streamlit and pure python.\n",
        "\n",
        "[Streamlit](https://streamlit.io/) is a simple python-based framework for developing interactive ML apps that run python on the backend. You define your frontend using a combination of markdown and widgets such as text inputs, charts, checkboxes, etc.\n",
        "\n",
        "You can install streamlit as `pip install streamlit`, but __please switch from colab to your local computer__, otherwise you won't be able to view the results your work!\n",
        "\n",
        "Let's walk through a simple streamlit app:\n",
        "\n",
        "```python\n",
        "import streamlit as st\n",
        "st.set_page_config(page_title=\"A + B calculator pro max\", layout=\"centered\")\n",
        "st.markdown(\"## Hello, world!\")\n",
        "a = st.number_input(\"A =\", value=0)\n",
        "b = st.number_input(\"B =\", value=0)\n",
        "a_plus_b = a + b\n",
        "st.markdown(f\"$A + B = {a_plus_b}$\")\n",
        "```\n",
        "\n",
        "You can start this app on your computer like this:\n",
        "```streamlit run app.py``` where app.py is your python file name.\n",
        "\n",
        "![img](https://i.imgur.com/GUTjZQC.png)\n",
        "\n",
        "\n",
        "You can host this app in three ways: [streamlit cloud](https://streamlit.io/cloud), [huggingface spaces](https://huggingface.co/new-space) or on your own server. All of them are possible for free, but we recommend the middle one out as it is the simplest.\n",
        "\n",
        "You can find the full tutorial on hosting with huggingface spaces here: https://huggingface.co/docs/hub/spaces"
      ],
      "metadata": {
        "id": "9USIonXb43h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eaIl1o8e-njE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
