{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in colab, please run:\n",
    "!pip install transformers sentence-transformers datasets rouge_score nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [In-class version] Summarization\n",
    "\n",
    "This notebook will guide you through the basics of test summarization within a nlp_cource seminar.\n",
    "\n",
    "Later this day, the notebook will be replaced by a longer \"homework\" version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "data = datasets.load_dataset(\"multi_news\")\n",
    "train_dataset, val_dataset = data['train'], data['validation']\n",
    "\n",
    "SEMINAR_MODE = True\n",
    "\n",
    "if SEMINAR_MODE:\n",
    "    val_dataset = [val_dataset[i] for i in range(0, len(val_dataset), 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example = val_dataset[42]\n",
    "sources = tuple(filter(len, map(str.strip, example['document'].split('|||||'))))\n",
    "\n",
    "for i, source in enumerate(sources):\n",
    "    print(f\"SOURCE #{i}: {source}\\n{'=' * 50}\\n\")\n",
    "print(\"SUMMARY:\\n\", example['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 100\n",
    "\n",
    "def summarize_baseline(doc: str, max_words=MAX_WORDS):\n",
    "    sentences = nltk.sent_tokenize('\\n'.join(doc.split('|||||')))\n",
    "    summary = []\n",
    "    num_words = 0\n",
    "    \n",
    "    for sent in sentences:\n",
    "        sentence_length = len(nltk.word_tokenize(sent))\n",
    "        if num_words + sentence_length > max_words:\n",
    "            break\n",
    "        num_words += sentence_length\n",
    "        summary.append(sent)\n",
    "    return ' '.join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summarize_baseline(val_dataset[42]['document']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, but is it any good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from tqdm.auto import trange\n",
    "\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(target='The quick brown fox jumps over the lazy dog',\n",
    "                      prediction='The quick brown dog jumps on the log.')\n",
    "print(scores['rouge1'].fmeasure, scores['rougeL'].fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge_f1(dataset, predictions):\n",
    "    \n",
    "    <YOUR CODE: compute mean f-measures for Rouge-1 and Rouge-L>\n",
    "    return mean_r1, mean_rL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_predictions = [summarize_baseline(row['document']) for row in val_dataset]\n",
    "baseline_rouge1, baseline_rougeL = compute_rouge_f1(val_dataset, baseline_predictions)\n",
    "\n",
    "print(\"Rouge-1:\", baseline_rouge1)\n",
    "print(\"Rouge-L:\", baseline_rougeL)\n",
    "\n",
    "if SEMINAR_MODE:\n",
    "    assert abs(baseline_rouge1 - 0.26632) < 1e-4 and abs(baseline_rougeL - 0.14617) < 1e-4\n",
    "    print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural extractive summarization\n",
    "\n",
    "![](https://i.imgur.com/kkrzeq7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(lowercase=True, max_features=50_000)\n",
    "vectorizer.fit([item['document'] for item in train_dataset])\n",
    "encode_func = lambda texts: vectorizer.transform(texts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = val_dataset[42]\n",
    "documents = tuple(filter(len, map(str.strip, doc['document'].split('|||||'))))\n",
    "\n",
    "sentences_by_doc = [nltk.sent_tokenize(doc) for doc in documents]\n",
    "sentences = [sent for document in sentences_by_doc for sent in document]\n",
    "sentence_lengths = np.array([len(nltk.word_tokenize(sent)) for sent in sentences])\n",
    "\n",
    "sentence_embeddings = encode_func(sentences)\n",
    "document_embeddings = encode_func(list(map('\\n'.join, sentences_by_doc)))\n",
    "print(\"Sentence embeddings shape:\", sentence_embeddings.shape)\n",
    "print(\"Document embedding shape:\", document_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarities between each pair of sentences\n",
    "sentence_similarities = <YOUR CODE HERE>\n",
    "\n",
    "# ... and also between each sentence and each document\n",
    "document_similarities = <YOUR CODE HERE>\n",
    "\n",
    "assert sentence_similarities.shape == (len(sentences), len(sentences))\n",
    "assert sentence_similarities.shape == (len(sentences), len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.title(\"Sentence-to-sentence similarities\")\n",
    "plt.imshow(sentence_similarities)\n",
    "plt.show()\n",
    "plt.title(\"Sentence-to-document similarities\")\n",
    "plt.imshow(document_similarities.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "networkx.draw_networkx(networkx.from_numpy_array(sentence_similarities > 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_summary_greedy(sentences, sentence_scores, sentence_similarities, sentence_lengths,\n",
    "                          max_words=MAX_WORDS, sim_threshold=0.9):\n",
    "    assert sentence_scores.shape == (len(sentences),)\n",
    "    chosen_sentences = []\n",
    "    max_similarities = np.zeros(len(sentences))\n",
    "    num_words = 0\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        mask = (sentence_lengths <= (max_words - num_words)) & (max_similarities < sim_threshold)\n",
    "        if not np.any(mask):\n",
    "            break\n",
    "\n",
    "        best_sentence_index = np.argmax(sentence_scores * mask)\n",
    "\n",
    "        chosen_sentences.append(sentences[best_sentence_index])\n",
    "\n",
    "\n",
    "        max_similarities = np.maximum(max_similarities, sentence_similarities[best_sentence_index])\n",
    "        num_words += sentence_lengths[best_sentence_index]\n",
    "    \n",
    "    return chosen_sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = sentence_similarities.mean(axis=-1)\n",
    "\n",
    "summary_sentences = choose_summary_greedy(\n",
    "    sentences, sentence_scores, sentence_similarities, sentence_lengths,\n",
    "    max_words=MAX_WORDS, sim_threshold=0.7)\n",
    "print(summary_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_one(document, max_words=MAX_WORDS, sim_threshold=0.7):\n",
    "    documents = tuple(filter(len, map(str.strip, document.split('|||||'))))\n",
    "\n",
    "    sentences_by_doc = [nltk.sent_tokenize(doc) for doc in documents]\n",
    "    sentences = [sent for document in sentences_by_doc for sent in document]\n",
    "    sentence_lengths = np.array([len(nltk.word_tokenize(sent)) for sent in sentences])\n",
    "    \n",
    "    # use encode_func to compute embedding matrices\n",
    "    sentence_embeddings = <YOUR CODE HERE>\n",
    "    document_embeddings = <YOUR CODE HERE>\n",
    "\n",
    "    # compute pairwise similarities between sentences and sentence-document pairs\n",
    "    sentence_similarities = <YOUR CODE HERE>\n",
    "    document_similarities = <YOUR CODE HERE>\n",
    "    \n",
    "    \n",
    "    # Compute the scores s.t. higher score corresponds to better sentences.\n",
    "    # There are many ways to devise such a function, try them for yourself and see which works best.\n",
    "    # Here's a few inspirations:\n",
    "    # - mean similarity to 3 nearest sentences [please start with this one]\n",
    "    # - page-rank scores that use similarity matrix as connectivity matrix\n",
    "    # - distance to the nearest cluster in embedding space using k-means clustering\n",
    "    sentence_scores = <YOUR CODE HERE>\n",
    "    \n",
    "    summary_sentences = choose_summary_greedy(\n",
    "        sentences, sentence_scores, sentence_similarities, sentence_lengths,\n",
    "        max_words=max_words, sim_threshold=sim_threshold)\n",
    "    \n",
    "    return '\\n'.join(summary_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(summarize_one(val_dataset[2]['document']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_summaries = []\n",
    "for i in trange(len(val_dataset)):\n",
    "    our_summaries.append(summarize_one(val_dataset[i]['document']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_rouge1, our_rougel = compute_rouge_f1(val_dataset, our_summaries)\n",
    "\n",
    "print(\"Rouge-1:\", our_rouge1)\n",
    "print(\"Rouge-L:\", our_rougel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we do better than TF-IDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE').train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1, emb2, emb3, emb4 = model.encode(\n",
    "    ['Hello, world!', 'Greeting, universe!', 'Hello, John!', \"A cat sat on the mat.\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sim(hello world, hello john) =\", emb1 @ emb3)\n",
    "print(\"Sim(hello world, greetings universe) =\", emb1 @ emb2)\n",
    "print(\"Sim(hello world, a cat sat on the mat)=\", emb1 @ emb4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_func = model.encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = val_dataset[50]\n",
    "documents = tuple(filter(len, map(str.strip, doc['document'].split('|||||'))))\n",
    "\n",
    "sentences_by_doc = [nltk.sent_tokenize(doc) for doc in documents]\n",
    "sentences = [sent for document in sentences_by_doc for sent in document]\n",
    "sentence_lengths = np.array([len(nltk.word_tokenize(sent)) for sent in sentences])\n",
    "\n",
    "sentence_embeddings = encode_func(sentences)\n",
    "document_embeddings = encode_func(list(map('\\n'.join, sentences_by_doc)))\n",
    "print(\"Sentence embeddings shape:\", sentence_embeddings.shape)\n",
    "print(\"Document embedding shape:\", document_embeddings.shape)\n",
    "\n",
    "sentence_similarities = sentence_embeddings @ sentence_embeddings.T\n",
    "document_similarities = sentence_embeddings @ document_embeddings.T\n",
    "\n",
    "plt.title(\"Sentence-to-sentence similarities\")\n",
    "plt.imshow(sentence_similarities)\n",
    "plt.show()\n",
    "plt.title(\"Sentence-to-document similarities\")\n",
    "plt.imshow(document_similarities.T)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_summaries = []\n",
    "for i in trange(len(val_dataset)):\n",
    "    our_summaries.append(summarize_one(val_dataset[i]['document']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "our_rouge1, our_rougel = compute_rouge_f1(val_dataset, our_summaries)\n",
    "\n",
    "print(\"Rouge-1:\", our_rouge1)\n",
    "print(\"Rouge-L:\", our_rougel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the cavalry!\n",
    "\n",
    "[Pegasus](https://arxiv.org/abs/1912.08777) is an *abstractive* summarization model based on a large pre-trained transformer. Before doing any summarizaton, the model is pre-trained on a combination of MLM and a specialized objective called Gap Sentence Generation: predicting an entire sentence omitted from the middle of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "pegasus = transformers.pipeline(\"summarization\", \"google/pegasus-multi_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = example['document'].split('|||||')[0]\n",
    "print(\"SUMMARY:\", pegasus([document], min_length=5, max_length=100)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
